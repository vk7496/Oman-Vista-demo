import streamlit as st
import requests
import folium
from streamlit_folium import st_folium
import feedparser

# -------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª API
# -------------------
PEXELS_API = "YOUR_PEXELS_API_KEY"
UNSPLASH_ACCESS_KEY = "YOUR_UNSPLASH_API_KEY"

# -------------------
# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ø¹Ú©Ø³ Ø§Ø² Pexels
# -------------------
def fetch_pexels(query):
    headers = {"Authorization": PEXELS_API}
    url = f"https://api.pexels.com/v1/search?query={query}&per_page=1"
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            data = r.json()
            if data["photos"]:
                return data["photos"][0]["src"]["large"]
    except:
        return None
    return None

# -------------------
# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ø¹Ú©Ø³ Ø§Ø² Unsplash
# -------------------
def fetch_unsplash(query):
    url = f"https://api.unsplash.com/search/photos?query={query}&client_id={UNSPLASH_ACCESS_KEY}&per_page=1"
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            if data["results"]:
                return data["results"][0]["urls"]["regular"]
    except:
        return None
    return None

# -------------------
# Ø²Ø¨Ø§Ù†
# -------------------
lang = st.sidebar.radio("ğŸŒ Language | Ø§Ù„Ù„ØºØ©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

if lang == "English":
    title = "ğŸŒ OmanVista - AI Tourism Explorer"
    subtitle = "Discover hidden attractions and cultural sites across Oman"
    search_placeholder = "Enter a city (e.g. Muscat, Salalah)"
    search_button = "Search"
    map_title = "ğŸ“ Map of Attractions"
    chatbot_title = "ğŸ’¬ AI Travel Assistant"
    reddit_title = "ğŸ“° Latest from Reddit"
elif lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
    title = "ğŸŒ Ø¹Ù…Ø§Ù† ÙÙŠØ³ØªØ§ - Ù…Ø³ØªÙƒØ´Ù Ø§Ù„Ø³ÙŠØ§Ø­Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
    subtitle = "Ø§ÙƒØªØ´Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ù…Ø®ÙÙŠØ© ÙˆØ§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¹Ù…Ø§Ù†"
    search_placeholder = "Ø£Ø¯Ø®Ù„ Ù…Ø¯ÙŠÙ†Ø© (Ù…Ø«Ø§Ù„: Ù…Ø³Ù‚Ø·ØŒ ØµÙ„Ø§Ù„Ø©)"
    search_button = "Ø¨Ø­Ø«"
    map_title = "ğŸ“ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ©"
    chatbot_title = "ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø³ÙØ± Ø§Ù„Ø°ÙƒÙŠ"
    reddit_title = "ğŸ“° Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø±ÙŠØ¯ÙŠØª"

# -------------------
# Ù‡Ø¯Ø± Ø¨Ø§ Ø¨Ú©â€ŒÚ¯Ø±Ø§Ù†Ø¯
# -------------------
st.markdown(
    f"""
    <div style="background-image: url('https://upload.wikimedia.org/wikipedia/commons/5/5d/Muscat_Oman_sunset.jpg');
                background-size: cover; padding: 70px; border-radius: 15px;">
        <h1 style="color: white; text-align: center;">{title}</h1>
        <h3 style="color: white; text-align: center;">{subtitle}</h3>
    </div>
    """,
    unsafe_allow_html=True
)

st.write("")

# -------------------
# Ø¬Ø³ØªØ¬Ùˆ Ø´Ù‡Ø±
# -------------------
city = st.text_input(search_placeholder, "")
if st.button(search_button):
    img_url = fetch_pexels(city) or fetch_unsplash(city)
    if img_url:
        st.image(img_url, caption=city.title(), use_container_width=True)
        if city.lower() == "muscat":
            st.write("Muscat is known for its coastline, souqs, and Sultan Qaboos Grand Mosque.")
        elif city.lower() == "salalah":
            st.write("Salalah is famous for its Khareef season, lush mountains, and frankincense history.")
        else:
            st.write(f"Showing results for {city}")
    else:
        st.warning("âš ï¸ No image found. Try another city.")

# -------------------
# Ù†Ù‚Ø´Ù‡
# -------------------
st.subheader(map_title)
m = folium.Map(location=[20.0, 57.0], zoom_start=6)
folium.Marker([23.5880, 58.3829], popup="Muscat").add_to(m)
folium.Marker([17.0194, 54.0897], popup="Salalah").add_to(m)
st_folium(m, width=700, height=450)

# -------------------
# Ú†Øªâ€ŒØ¨Ø§Øª Ø³Ø§Ø¯Ù‡
# -------------------
st.subheader(chatbot_title)
q = st.text_input("Ask about Oman âœ¨ | Ø§Ø³Ø£Ù„ Ø¹Ù† Ø¹Ù…Ø§Ù†")
if q:
    if "muscat" in q.lower() or "Ù…Ø³Ù‚Ø·" in q:
        st.success("Muscat is Omanâ€™s vibrant capital ğŸ™ï¸ blending tradition with modern life.")
    elif "salalah" in q.lower() or "ØµÙ„Ø§Ù„Ø©" in q:
        st.success("Salalah is known for its Khareef ğŸŒ´ and lush green landscapes.")
    else:
        st.info("I donâ€™t have info yet. Try Muscat or Salalah ğŸ˜‰")

# -------------------
# Reddit News (RSS)
# -------------------
st.subheader(reddit_title)
feeds = ["https://www.reddit.com/r/oman/.rss", "https://www.reddit.com/r/travel/.rss"]

for f in feeds:
    feed = feedparser.parse(f)
    st.markdown(f"#### {f}")
    for entry in feed.entries[:3]:
        st.markdown(f"- [{entry.title}]({entry.link})")
